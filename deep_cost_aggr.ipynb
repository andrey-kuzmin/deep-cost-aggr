{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as sio\n",
    "import time\n",
    "\n",
    "import lasagne.layers as ll\n",
    "\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Pool2DLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import TransposedConv2DLayer\n",
    "\n",
    "import lasagne.updates\n",
    "\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.nonlinearities import rectify\n",
    "from lasagne.nonlinearities import sigmoid\n",
    "\n",
    "# max allowed disparity\n",
    "d_max = 256;\n",
    "\n",
    "# image dimensions\n",
    "h = 370;\n",
    "w = 1224;\n",
    "\n",
    "# input variables\n",
    "I_l_color_batch = T.tensor4(dtype='float32');\n",
    "lr = T.scalar(dtype='float32');\n",
    "sigma = T.scalar(dtype='float32');\n",
    "\n",
    "E_total = T.tensor3(dtype='float32');     \n",
    "\n",
    "D_gt = T.matrix('D_gt',dtype='int32'); \n",
    "\n",
    "nl_input = InputLayer(shape=(1, 3, h, w), input_var=I_l_color_batch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this part is a modified version of the CNN based edge detector based on\n",
    "# Holistically-nested edge detection, Xie et al. CVPR 2015\n",
    "\n",
    "pad_sz = 34;\n",
    "n_scales = 5;\n",
    "\n",
    "# 1/2 of the feature maps is used compared to the original achitecture\n",
    "# in order to improve the computational performance\n",
    "mult = 0.5;\n",
    "\n",
    "# scale 1\n",
    "l_conv1_1 = ConvLayer(nl_input, name = \"l_conv1_1\", num_filters=64*mult, filter_size=3, pad=pad_sz+1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv1_2 = ConvLayer(l_conv1_1, name = \"l_conv1_2\", num_filters=64*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "conv1_2_out = ll.get_output(l_conv1_2).dimshuffle((0,1,3,2));\n",
    "\n",
    "nl_conv_out = InputLayer(shape=(1,64*mult,None,None), input_var=conv1_2_out);\n",
    "\n",
    "# transpose the image in order to circumvent the cuDNN restriction on the image size\n",
    "l_pool1 = Pool2DLayer(nl_conv_out, name = 'l_pool1', stride=2, pool_size=2, mode='max', ignore_border=False);\n",
    "\n",
    "pool1_out = ll.get_output(l_pool1).dimshuffle((0,1,3,2));\n",
    "\n",
    "nl_pool_out = InputLayer(shape=(1,64*mult,None,None), input_var=pool1_out);\n",
    "\n",
    "# scale 2\n",
    "l_conv2_1 = ConvLayer(nl_pool_out, name = \"l_conv2_1\", num_filters=128*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv2_2 = ConvLayer(l_conv2_1, name = \"l_conv2_2\", num_filters=128*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_pool2 = Pool2DLayer(l_conv2_2, name = 'l_pool2', stride=2, pool_size=2, mode='max', ignore_border=False);\n",
    "# scale 3\n",
    "l_conv3_1 = ConvLayer(l_pool2, name = \"l_conv3_1\", num_filters=256*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv3_2 = ConvLayer(l_conv3_1, name = \"l_conv3_2\", num_filters=256*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv3_3 = ConvLayer(l_conv3_2, name = \"l_conv3_3\", num_filters=256*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_pool3 = Pool2DLayer(l_conv3_3, name = 'l_pool3', stride=2, pool_size=2, mode='max', ignore_border=False);\n",
    "# scale 4\n",
    "l_conv4_1 = ConvLayer(l_pool3, name = \"l_conv4_1\", num_filters=512*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv4_2 = ConvLayer(l_conv4_1, name = \"l_conv4_2\", num_filters=512*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv4_3 = ConvLayer(l_conv4_2, name = \"l_conv4_3\", num_filters=512*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_pool4 = Pool2DLayer(l_conv4_3, name = 'l_pool3', stride=2, pool_size=2, mode='max', ignore_border=False);\n",
    "# scale 5\n",
    "l_conv5_1 = ConvLayer(l_pool4, name = \"l_conv5_1\", num_filters=512*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv5_2 = ConvLayer(l_conv5_1, name = \"l_conv5_2\", num_filters=512*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "l_conv5_3 = ConvLayer(l_conv5_2, name = \"l_conv5_3\", num_filters=512*mult, filter_size=3, pad=1,\n",
    "                    nonlinearity=rectify, flip_filters=False);\n",
    "\n",
    "n_maps_upsample = 8;\n",
    "\n",
    "# upsampling\n",
    "l_score_dsn1 = ConvLayer(l_conv1_2, name = \"l_score_dsn1\", num_filters=n_maps_upsample, filter_size=1, pad=0, nonlinearity=None);\n",
    "\n",
    "l_score_dsn2 = ConvLayer(l_conv2_2, name = \"l_score_dsn2\", num_filters=n_maps_upsample, filter_size=1, pad=0, nonlinearity=None);\n",
    "l_upsample2 = TransposedConv2DLayer( l_score_dsn2, name = \"l_upsample2\",num_filters=n_maps_upsample, filter_size=4, stride=2, nonlinearity=None); \n",
    "\n",
    "l_score_dsn3 = ConvLayer(l_conv3_3, name = \"l_score_dsn3\", num_filters=n_maps_upsample, filter_size=1, pad=0, nonlinearity=None);\n",
    "l_upsample4 = TransposedConv2DLayer(l_score_dsn3, name = \"l_upsample4\",num_filters=n_maps_upsample, filter_size=8, stride=4, nonlinearity=None);  \n",
    "\n",
    "l_score_dsn4 = ConvLayer(l_conv4_3, name = \"l_score_dsn4\", num_filters=n_maps_upsample, filter_size=1, pad=0, nonlinearity=None);\n",
    "l_upsample8 = TransposedConv2DLayer(l_score_dsn4, name = \"l_upsample8\",num_filters=n_maps_upsample, filter_size=16, stride=8, nonlinearity=None); \n",
    "\n",
    "l_score_dsn5 = ConvLayer(l_conv5_3, name = \"l_score_dsn5\", num_filters=n_maps_upsample, filter_size=1, pad=0, nonlinearity=None);\n",
    "l_upsample16 = TransposedConv2DLayer(l_score_dsn5, name = \"l_upsample16\",num_filters=n_maps_upsample, filter_size=32, stride=16, nonlinearity=None);  \n",
    "\n",
    "# multi-scale linear combination\n",
    "# this code reproduces the original cropping behaviour of the caffe-hed code\n",
    "# see https://github.com/s9xie/hed for details\n",
    "edges1_matr = ll.get_output(l_score_dsn1)[:,:,pad_sz:pad_sz+h,pad_sz:pad_sz+w];\n",
    "edges2_matr = ll.get_output(l_upsample2)[:,:,pad_sz+1:pad_sz+1+h,pad_sz+1:pad_sz+1+w];\n",
    "edges3_matr = ll.get_output(l_upsample4)[:,:,pad_sz+2:pad_sz+2+h,pad_sz+2:pad_sz+2+w];\n",
    "edges4_matr = ll.get_output(l_upsample8)[:,:,pad_sz+4:pad_sz+4+h,pad_sz+4:pad_sz+4+w];\n",
    "edges5_matr = ll.get_output(l_upsample16)[:,:,pad_sz+8:pad_sz+8+h,pad_sz+8:pad_sz+8+w];\n",
    "\n",
    "C = T.concatenate([edges1_matr,edges2_matr,edges3_matr,edges4_matr,edges5_matr],axis=1);\n",
    "\n",
    "C_nl = InputLayer(shape=(1,n_scales*n_maps_upsample,h,w), input_var=C);\n",
    "\n",
    "l_conv_final = ConvLayer(C_nl, name = \"l_conv_final\",num_filters=2, filter_size=1, pad=0, \n",
    "                         nonlinearity=sigmoid);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Trained Domain Transform (RNN guided by the edge detection CNN)\n",
    "\n",
    "def rec_filter_func(x_t,w_t,y_tm1):\n",
    "    y_t = (1 - w_t) * x_t + w_t * y_tm1;\n",
    "    return y_t\n",
    "\n",
    "def DT_horizontal(E_total, W_matrix_sig_h):\n",
    "    E_filt_init_rot_clkws = (E_total[::-1]).dimshuffle((1,0,2));\n",
    "\n",
    "    W_matrix_rot_clkws = (W_matrix_sig_h[::-1]).dimshuffle((1,0,2));\n",
    "\n",
    "    E_filt_leftright, updates = theano.scan(fn=rec_filter_func, \n",
    "                                         sequences=[E_filt_init_rot_clkws[1:],W_matrix_rot_clkws[1:]],\n",
    "                                         outputs_info = [dict(initial = E_filt_init_rot_clkws[0], taps = [-1])],\n",
    "                                         n_steps=w-1, allow_gc = False)\n",
    "\n",
    "    E_filt_leftright_fullsize = T.concatenate((E_filt_init_rot_clkws[np.newaxis,0,:,:],E_filt_leftright));\n",
    "\n",
    "    E_filt_leftright_flipped = E_filt_leftright_fullsize[::-1];\n",
    "\n",
    "    E_filt_rightleft, updates = theano.scan(fn=rec_filter_func, \n",
    "                                            sequences=[E_filt_leftright_flipped[1:],W_matrix_rot_clkws[-2::-1]],\n",
    "                                            outputs_info = [dict(initial = E_filt_leftright_flipped[0], taps = [-1])],\n",
    "                                            n_steps=w-1, allow_gc = False)\n",
    "\n",
    "    E_filt_rightleft_fullsize = T.concatenate((E_filt_leftright_flipped[np.newaxis,0,:,:],E_filt_rightleft));\n",
    "\n",
    "    E_filt_rightleft_fullsize_flipped = E_filt_rightleft_fullsize[::-1];\n",
    "\n",
    "    E_filt_init = E_filt_rightleft_fullsize_flipped.dimshuffle((1,0,2))[::-1];\n",
    "    \n",
    "    return E_filt_init;\n",
    "\n",
    "def DT_vertical(E_filt_init, W_matrix_sig_v):\n",
    "    E_filt_updown, updates = theano.scan(fn=rec_filter_func, \n",
    "                                         sequences=[E_filt_init[1:],W_matrix_sig_v[1:]],\n",
    "                                         outputs_info = [dict(initial = E_filt_init[0], taps = [-1])],\n",
    "                                         n_steps=h-1, allow_gc = False)\n",
    "\n",
    "    E_filt_updown_fullsize = T.concatenate((E_filt_init[np.newaxis,0,:,:],E_filt_updown));\n",
    "\n",
    "    E_filt_updown_flipped = E_filt_updown_fullsize[::-1];\n",
    "\n",
    "    E_filt_downup, updates = theano.scan(fn=rec_filter_func, \n",
    "                                         sequences=[E_filt_updown_flipped[1:],W_matrix_sig_v[-2::-1]],\n",
    "                                         outputs_info = [dict(initial = E_filt_updown_flipped[0], taps = [-1])],\n",
    "                                         n_steps=h-1, allow_gc = False)\n",
    "\n",
    "    E_filt_downup_fullsize = T.concatenate((E_filt_updown_flipped[np.newaxis,0,:,:],E_filt_downup));\n",
    "\n",
    "    E_filt_final = E_filt_downup_fullsize[::-1];\n",
    "    \n",
    "    return E_filt_final;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# horizontal and vertical edge maps\n",
    "edges_matr_v = (ll.get_output(l_conv_final))[0,0,0:h,0:w];\n",
    "edges_matr_h = (ll.get_output(l_conv_final))[0,1,0:h,0:w];\n",
    "\n",
    "edges_h = edges_matr_h[:,:,np.newaxis];\n",
    "dt_w_h = T.exp(-1.0 * sigma * edges_h);\n",
    "\n",
    "edges_v = edges_matr_v[:,:,np.newaxis];\n",
    "dt_w_v = T.exp(-1.0 * sigma * edges_v);\n",
    "   \n",
    "W_matrix_sig_h = dt_w_h;\n",
    "W_matrix_sig_v = dt_w_v;\n",
    "\n",
    "E_input = E_total;\n",
    "\n",
    "E_filt_hor = DT_horizontal(E_input,W_matrix_sig_h);\n",
    "E_filt_vert = DT_vertical(E_filt_hor,W_matrix_sig_v);\n",
    "\n",
    "E_output = E_filt_vert;\n",
    "\n",
    "E_filt_final = E_output;\n",
    "\n",
    "# Winner-takes-all disparity selection\n",
    "\n",
    "D = T.zeros((h,w),dtype='int32');\n",
    "\n",
    "for j in range(1,d_max):\n",
    "    D = T.set_subtensor(D[:,j],(E_filt_final[:,j,0:j]).argmin(axis=1));\n",
    "    \n",
    "D = T.set_subtensor(D[:,d_max:],(E_filt_final[:,d_max:,:]).argmin(axis=2));\n",
    "\n",
    "theano_disp_fn = theano.function(inputs=[I_l_color_batch,E_total,sigma], outputs=[D]);\n",
    "\n",
    "# One-hot vector for each ground truth disparity\n",
    "\n",
    "E_filt_lin = T.reshape(E_filt_final[:,:,:],(w*h,d_max+1));\n",
    "\n",
    "E_filt_lin_sm = T.nnet.softmax(-1.0*E_filt_lin);\n",
    "\n",
    "hw_index = range(0,w*h);\n",
    "\n",
    "d_gt_center = D_gt[:,:].flatten();\n",
    "\n",
    "D_gt_matr = T.zeros(((w)*h,d_max+1), dtype='float32');\n",
    "D_gt_matr = T.inc_subtensor(D_gt_matr[(hw_index,d_gt_center)],1.0);\n",
    "\n",
    "D_mask_vec = T.clip(d_gt_center,0,1);\n",
    "\n",
    "# Cross-entropy loss\n",
    "cross_entropy = T.nnet.categorical_crossentropy(E_filt_lin_sm,D_gt_matr);\n",
    "\n",
    "L = (D_mask_vec*cross_entropy).mean();\n",
    "\n",
    "list_layers = [l_conv_final, l_score_dsn1, l_upsample2, l_upsample4, l_upsample8, l_upsample16, l_pool1];\n",
    "params_lasagne = []\n",
    "for l in list_layers:\n",
    "    params_lasagne = params_lasagne + ll.get_all_params(l);\n",
    "\n",
    "params_lasagne = list(set(params_lasagne));\n",
    "\n",
    "updates_lasagne = lasagne.updates.adam(L, params_lasagne, learning_rate=lr);\n",
    "\n",
    "theano_train_fn = theano.function(inputs=[I_l_color_batch,E_total,D_gt,sigma,lr], \n",
    "                                  outputs=[L,D,edges_matr_v,edges_matr_h], \n",
    "                                  updates=updates_lasagne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_hed_rgb = np.array((104.00698793,116.66876762,122.67891434));\n",
    "\n",
    "def load_cnn_weights(params_file):\n",
    "    params = np.load(params_file)['names']\n",
    "    param_names = [p for p in params]\n",
    "\n",
    "    params = np.load(params_file)['values']\n",
    "    param_vals = [p.astype(np.float32) for p in params]\n",
    "\n",
    "    dict_vals = dict(zip(param_names, param_vals))\n",
    "\n",
    "    for p in params_lasagne:\n",
    "        v = dict_vals[p.name];\n",
    "        \n",
    "        if p.get_value().shape != v.shape:\n",
    "            raise ValueError(\"mismatch: parameter has shape %r but value to \"\n",
    "                             \"set has shape %r\" %\n",
    "                             (p.get_value().shape, v.shape))\n",
    "        else:\n",
    "            p.set_value(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CUDA functions for the data term (census + SAD)\n",
    "tensor_bnd_const_val = 18.35;\n",
    "tensor_bnd_const_zero_val = 0;\n",
    "\n",
    "sigma_val = 4.0;\n",
    "\n",
    "coef_total = 120.0;\n",
    "coef_sad = coef_total * 0.2 / 3.0 / 255.0;\n",
    "coef_census = coef_total * 0.8 / 49.0 / 3.0;\n",
    "\n",
    "n_el = h*w*(d_max+1);\n",
    "n_ch_color = 3;\n",
    "n_ch_gray  = 1;\n",
    "\n",
    "# 7x7 census transform\n",
    "wnd_half_census = 3;\n",
    "# 1x1 sum of absolute differences\n",
    "wnd_half_sad = 0;\n",
    "\n",
    "import theano.misc.pycuda_init\n",
    "import pycuda\n",
    "import pycuda.driver as drv\n",
    "import pycuda.gpuarray\n",
    "from pycuda.compiler import SourceModule\n",
    "import theano.sandbox.cuda as cuda_ndarray\n",
    "\n",
    "mod_src_file = open('./cuda/stereo_utils.cu', 'r')\n",
    "mod = SourceModule(mod_src_file.read())\n",
    "    \n",
    "census_func_pycuda = mod.get_function(\"census\")\n",
    "sad_func_pycuda = mod.get_function(\"sad_color\")\n",
    "linear_comb_func_pycuda = mod.get_function(\"linear_comb\")\n",
    "outlier_detection_func_pycuda = mod.get_function(\"outlier_detection\");\n",
    "interpolate_mismatch_func_pycuda = mod.get_function(\"interpolate_mismatch\");\n",
    "interpolate_occlusion_func_pycuda = mod.get_function(\"interpolate_occlusion\");\n",
    "\n",
    "def data_term(I_l_val,I_r_val,g_vol_sad,g_vol_census,g_vol_total):\n",
    "    I_l_gray = rgb2gray(I_l_val);\n",
    "    I_r_gray = rgb2gray(I_r_val);\n",
    "\n",
    "    g_Il_color = cuda_ndarray.CudaNdarray(np.transpose(I_l_val,(2,0,1)).astype('float32'))\n",
    "    g_Ir_color = cuda_ndarray.CudaNdarray(np.transpose(I_r_val,(2,0,1)).astype('float32'))\n",
    "    g_Il_gray = cuda_ndarray.CudaNdarray(I_l_gray.astype('float32'))\n",
    "    g_Ir_gray = cuda_ndarray.CudaNdarray(I_r_gray.astype('float32'))\n",
    "    \n",
    "    census_func_pycuda(\n",
    "        g_Il_gray,g_Ir_gray,g_vol_census,np.int32(n_el),np.int32(n_ch_gray),np.int32(h),np.int32(w),\n",
    "        np.int32(wnd_half_census),np.float32(tensor_bnd_const_zero_val), \n",
    "        block=(d_max+1,1,1), grid=(w, h))\n",
    "    \n",
    "    sad_func_pycuda(\n",
    "        g_Il_color,g_Ir_color,g_vol_sad,np.int32(n_el),np.int32(h),np.int32(w),\n",
    "        np.int32(wnd_half_sad),np.float32(tensor_bnd_const_val / coef_sad), \n",
    "        block=(d_max+1,1,1), grid=(w, h))\n",
    "\n",
    "    linear_comb_func_pycuda(\n",
    "        g_vol_sad,g_vol_census,g_vol_total,np.int32(n_el),np.float32(coef_sad),np.float32(coef_census), \n",
    "        block=(d_max+1,1,1), grid=(w, h))\n",
    "\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# auxiliary functions for KITTI 2015 data set\n",
    "\n",
    "import scipy.ndimage\n",
    "import os.path\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from skimage.color import rgb2gray\n",
    "from scipy import ndimage\n",
    "\n",
    "def load_disp(path):\n",
    "    import scipy.ndimage\n",
    "    return scipy.ndimage.imread(path)\n",
    "\n",
    "def load_kitti_2015_img_color(data_dir, index, occluded=False, test=False, future=False):\n",
    "    right = False\n",
    "    path_left = os.path.join(data_dir,'data_scene_flow','testing' if test else 'training',\n",
    "                             'image_3' if right else 'image_2',\n",
    "                             \"%06d_%2d.png\" % (index, 11 if future else 10))\n",
    "    \n",
    "    right = True;\n",
    "    path_right = os.path.join(data_dir,'data_scene_flow','testing' if test else 'training',\n",
    "                             'image_3' if right else 'image_2',\n",
    "                             \"%06d_%2d.png\" % (index, 11 if future else 10))\n",
    "    \n",
    "    path_disp = os.path.join(data_dir,'data_scene_flow','training',\n",
    "                             'disp_occ_0' if occluded else 'disp_noc_0',\n",
    "                             \"%06d_%2d.png\" % (index, 10))\n",
    "    \n",
    "    I_l = misc.imread(path_left);\n",
    "    I_r = misc.imread(path_right);\n",
    "    D_gt_val = (sp.ndimage.imread(path_disp)) / 256;\n",
    "    \n",
    "    I_l = I_l[0:h,0:w,:];\n",
    "    I_r = I_r[0:h,0:w,:];\n",
    "    D_gt_val = D_gt_val[0:h,0:w];\n",
    "    \n",
    "    I_l_color_val = I_l.astype(np.float32);\n",
    "    I_r_color_val = I_r.astype(np.float32);\n",
    "   \n",
    "    I_l_orig = np.copy(I_l);\n",
    "    I_r_orig = np.copy(I_r);\n",
    "    \n",
    "    I_l = I_l.astype(np.float32) - mean_hed_rgb;\n",
    "    I_r = I_r.astype(np.float32) - mean_hed_rgb;\n",
    "    \n",
    "    I_l_color_batch_val = np.transpose(I_l[np.newaxis,:,:,:],(0,3,1,2));\n",
    "    I_l_color_batch_val = np.float32(I_l_color_batch_val);\n",
    "    \n",
    "    I_r_color_batch_val = np.transpose(I_r[np.newaxis,:,:,:],(0,3,1,2));\n",
    "    I_r_color_batch_val = np.float32(I_r_color_batch_val);\n",
    "        \n",
    "    return (I_l_color_batch_val,I_r_color_batch_val,I_l_orig,I_r_orig,D_gt_val);\n",
    "\n",
    "def disp_error(D_gt_val,D_val):\n",
    "    h = D_gt_val.shape[0];\n",
    "    w = D_gt_val.shape[1];\n",
    "    \n",
    "    D_gt_mask_val = np.zeros((h,w));\n",
    "    D_gt_mask_val[D_gt_val > 0] = 1.0;\n",
    "\n",
    "    E = np.abs(D_val.astype('float32') - D_gt_val.astype('float32'));\n",
    "    err_numer = (E*D_gt_mask_val > 3).sum();\n",
    "\n",
    "    return float(err_numer) / max(((D_gt_val > 0.0).sum()),1)\n",
    "\n",
    "def test_error(rng_test):\n",
    "    n_img_test = len(rng_test);\n",
    "    err_vec_full = np.zeros((n_img_test,1),dtype=np.float32);\n",
    "    err_vec_leftright = np.zeros((n_img_test,1),dtype=np.float32);\n",
    "    err_vec_med = np.zeros((n_img_test,1),dtype=np.float32);\n",
    "    \n",
    "    g_vol_census = cuda_ndarray.CudaNdarray.zeros((h,w,d_max+1));\n",
    "    g_vol_sad = cuda_ndarray.CudaNdarray.zeros((h,w,d_max+1));\n",
    "    g_vol_total = cuda_ndarray.CudaNdarray.zeros((h,w,d_max+1));\n",
    "    \n",
    "    for idx in range(0,n_img_test):\n",
    "        i_img = rng_test[idx];\n",
    "       \n",
    "        occluded = True;\n",
    "        [I_l_color_batch_val,I_r_color_batch_val,I_l_val,I_r_val,D_gt_val] = load_kitti_2015_img_color('/media/hpc3_storage/akuzmin/KITTI/',i_img, occluded);\n",
    " \n",
    "        data_term(I_l_val,I_r_val,g_vol_sad,g_vol_census,g_vol_total);\n",
    "        [D_left_val] = theano_disp_fn(I_l_color_batch_val,g_vol_total,sigma_val);\n",
    "\n",
    "        data_term(I_r_val[:,::-1,:],I_l_val[:,::-1,:],g_vol_sad,g_vol_census,g_vol_total);\n",
    "        [D_right_val] = theano_disp_fn(I_r_color_batch_val[:,:,:,::-1],g_vol_total,sigma_val);\n",
    "        D_right_val = D_right_val[:,::-1];\n",
    "\n",
    "        g_img_outlier = cuda_ndarray.CudaNdarray.zeros((h,w))\n",
    "        g_d_left = cuda_ndarray.CudaNdarray(D_left_val.astype('float32'))\n",
    "        g_d_right = cuda_ndarray.CudaNdarray(D_right_val.astype('float32'))\n",
    "\n",
    "        outlier_detection_func_pycuda(\n",
    "            g_d_left,g_d_right,g_img_outlier,np.int32(n_el),np.int32(w),np.int32(d_max), \n",
    "            block=(1,1,1), grid=(w, h))\n",
    "\n",
    "        g_d_left_interp_occ = cuda_ndarray.CudaNdarray.zeros((h,w))\n",
    "        interpolate_occlusion_func_pycuda(\n",
    "            g_d_left,g_img_outlier,g_d_left_interp_occ,np.int32(n_el),np.int32(w), \n",
    "            block=(1,1,1), grid=(w, h))\n",
    "\n",
    "        g_d_left_interp_mis = cuda_ndarray.CudaNdarray.zeros((h,w))\n",
    "        interpolate_mismatch_func_pycuda(\n",
    "            g_d_left_interp_occ,g_img_outlier,g_d_left_interp_mis,np.int32(n_el),np.int32(h),np.int32(w), \n",
    "            block=(1,1,1), grid=(w, h))\n",
    "        \n",
    "        D_left_interp = np.asarray(g_d_left_interp_mis);\n",
    "        D_left_interp_med = ndimage.median_filter(D_left_interp, 5)\n",
    "        \n",
    "        erval_full = disp_error(D_gt_val,D_left_val);\n",
    "        erval_leftright = disp_error(D_gt_val,D_left_interp);\n",
    "        erval_med = disp_error(D_gt_val,D_left_interp_med);\n",
    "       \n",
    "        err_vec_full[idx] = erval_full;\n",
    "        err_vec_leftright[idx] = erval_leftright;\n",
    "        err_vec_med[idx] = erval_med;\n",
    "    \n",
    "    return (np.mean(err_vec_full),np.mean(err_vec_leftright),np.mean(err_vec_med))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set error (occluded)\n",
      "raw disparity error: 0.0765398\n",
      "error after the left-right check and median filter: 0.0538234\n"
     ]
    }
   ],
   "source": [
    "load_cnn_weights('./pretrained_model/deep_cost_aggr_pretrained_kitti.npz');\n",
    "\n",
    "rng_test = range(160,200);\n",
    "[test_err_full,test_err_leftright,test_err_med] = test_error(rng_test);\n",
    "            \n",
    "print 'validation set error (occluded)'\n",
    "print 'raw disparity error:', test_err_full\n",
    "print 'error after the left-right check and median filter:', test_err_med\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "load_cnn_weights('./pretrained_model/hed_pretrained_bsds.npz');\n",
    "\n",
    "rng_train = range(0,160);\n",
    "rng_test = range(160,200);\n",
    "\n",
    "n_iter = 10000;\n",
    "\n",
    "mu = np.float32(1.0E-4); \n",
    "\n",
    "d_err_vec_test_raw = np.zeros((n_iter,1));\n",
    "d_err_vec_test_leftright = np.zeros((n_iter,1));\n",
    "d_err_vec_test_med = np.zeros((n_iter,1));\n",
    "\n",
    "g_vol_census = cuda_ndarray.CudaNdarray.zeros((h,w,d_max+1));\n",
    "g_vol_sad = cuda_ndarray.CudaNdarray.zeros((h,w,d_max+1));\n",
    "g_vol_total = cuda_ndarray.CudaNdarray.zeros((h,w,d_max+1));\n",
    "\n",
    "for i_iter in range(0,n_iter):\n",
    "    if (np.mod(i_iter,10) == 0):\n",
    "            print 'iter ', i_iter\n",
    "            [test_err_raw,test_err_leftright,test_err_med] = test_error(rng_test);\n",
    "            d_err_vec_test_raw[i_iter] = test_err_raw;\n",
    "            d_err_vec_test_leftright[i_iter] = test_err_leftright;\n",
    "            d_err_vec_test_med[i_iter] = test_err_med;\n",
    "            \n",
    "            print 'validation set error (occluded)'\n",
    "            print 'raw disparity error:', test_err_raw\n",
    "            print 'error after the left-right check and median filter:', test_err_med\n",
    "    \n",
    "    img_idx = random.randint(rng_train[0], rng_train[-1]) \n",
    "\n",
    "    [I_l_color_batch_val,I_r_color_batch_val,I_l_val,I_r_val,D_gt_val] = load_kitti_2015_img_color('/media/hpc3_storage/akuzmin/KITTI/',img_idx);\n",
    "\n",
    "    data_term(I_l_val,I_r_val,g_vol_sad,g_vol_census,g_vol_total);\n",
    "    \n",
    "    # each single image is used as a batch for training as it contains many ground truth pixels\n",
    "    [L_val,D_val,E_h_val,E_v_val] = theano_train_fn(I_l_color_batch_val,g_vol_total,D_gt_val,sigma_val,mu)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
